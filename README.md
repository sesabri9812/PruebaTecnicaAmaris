# PruebaTecnicaAmaris


- Elaboracion de prueba tecnica para la empresa amaris usando herramientas de AWS.

## Punto 1 
### Arquitectura Implementada

- **Amazon S3**: Almacenamiento central del datalake con separaci√≥n en zonas *raw* y *processed*.
- **AWS Glue**: 
  - Crawlers para catalogar los datos.
  - Jobs ETL que transforman y mueven los datos desde raw a processed.
- **AWS Lake Formation**: Administraci√≥n de seguridad centralizada y permisos finos sobre datos.
- **Amazon Redshift**: Carga final de los datos procesados para an√°lisis.
- **Terraform**: Infraestructura como c√≥digo (IaC) para desplegar toda la arquitectura.

### Estructura del Repositorio

La organizaci√≥n del proyecto sigue una estructura clara para facilitar la navegaci√≥n:

#### Infraestructura
 **iac/** ‚Üí Contiene los archivos Terraform que definen la infraestructura en AWS.  
 `main.tf` ‚Üí Configuraci√≥n completa de los recursos en la nube.

#### Procesos ETL
 **scripts/** ‚Üí Incluye los Glue Jobs para el procesamiento de datos.  
 `clientes_etl.py` ‚Üí ETL para la informaci√≥n de clientes.  
 `proveedores_etl.py` ‚Üí ETL para datos de proveedores.  
 `transacciones_etl.py` ‚Üí ETL para registros de transacciones.

#### Evidencias
 **evidencias/** ‚Üí Almacena capturas de ejecuciones y resultados (opcional).

#### Datos de prueba
 **data/** ‚Üí Contiene los datos ficticios cargados a S3 para pruebas.

#### Documentaci√≥n
 `README.md` ‚Üí Archivo principal con la documentaci√≥n del proyecto.

#### Proceso de Ingesta y Transformaci√≥n

1. **Carga inicial a S3**:  
   Los datos CSV se almacenan en rutas como:
   - `s3://datalake-demo-pruebatecnica/raw/clientes/`
   - `s3://datalake-demo-pruebatecnica/raw/proveedores/`
   - `s3://datalake-demo-pruebatecnica/raw/transacciones/`

2. **Catalogaci√≥n con Glue Crawlers**:  
   Los crawlers detectan el esquema y crean tablas en el Glue Data Catalog (`energy_raw_db` y `energy_processed_db`).

3. **Transformaci√≥n con Glue Jobs**:  
   Los jobs procesan los datos (limpieza, transformaci√≥n de columnas, formatos) y los cargan en `s3://.../processed/`.

4. **Carga final a Redshift**:  
   Los datos procesados se cargan al DWH en Redshift para habilitar consultas anal√≠ticas.

5. **Gobierno de datos con Lake Formation**:  
   Se definen permisos finos a trav√©s de Lake Formation, permitiendo control detallado por base de datos y tabla.

### Herramientas y Tecnolog√≠as

- Terraform
- AWS S3, Glue, Redshift, IAM
- AWS Lake Formation
- Python (para scripts de ETL)
- GitHub Desktop (para versionamiento)

### Consideraciones de Seguridad

- Uso de IAM roles con permisos m√≠nimos necesarios.
- Cifrado en S3 habilitado (server-side encryption).
- Lake Formation como capa de gobernanza centralizada.

### Evidencias

Puedes incluir capturas de pantalla de:
- Bucket S3 con datos.
- Glue Crawlers y Jobs ejecutados.
- Glue Data Catalog con tablas creadas.
- Redshift con datos cargados.
- Consola de Lake Formation con permisos asignados.

### Autor

Este proyecto fue desarrollado como parte de una prueba t√©cnica para el rol de Ingeniero de Datos por Johan Sebastian Sanabria Simbaqueva.

---


## Punto 2 ‚Äì Arquitectura propuesta

Para conocer el dise√±o completo de la arquitectura, accede al siguiente enlace:

üîó [Dise√±o en Figma ‚Äì Arquitectura Venta de D√≥lares](https://www.figma.com/design/xrmoUCSBPbUnjoTTopgG0L/Arquitectura-Venta-dolares?node-id=0-1&t=h6twOG2eX2H2WWel-1)

### Componentes clave

| Servicio | Funci√≥n |
|----------|---------|
| **Amazon Kinesis** | Captura en tiempo real de transacciones de usuarios. |
| **AWS Lambda** | Procesamiento ligero e integraci√≥n con otros servicios. |
| **Amazon S3 (Datalake)** | Almacenamiento centralizado de eventos y datos hist√≥ricos. |
| **AWS Glue / Step Functions** | ETL batch para enriquecer datos e integrarlos al modelo. |
| **Amazon SageMaker** | Entrenamiento e inferencia del modelo de recomendaci√≥n. |
| **Amazon DynamoDB** | Portafolio en tiempo real de cada usuario. |
| **Amazon Redshift** | Almacenamiento anal√≠tico de transacciones hist√≥ricas. |
| **Amazon QuickSight** | Visualizaci√≥n de KPIs para analistas y stakeholders. |
| **Amazon SNS / Firebase** | Notificaciones personalizadas al usuario final. |

La arquitectura fue dise√±ada para ser **escalable**, **segura** y capaz de soportar picos de tr√°fico altos sin comprometer la latencia del sistema.

---

## Punto 3 ‚Äì Preguntas T√©cnicas

### 1. Experiencia como ingeniero de datos en AWS

Mi trayectoria se ha centrado en el sector bancario, desarrollando pipelines para ingestar, transformar y automatizar datos provenientes de servidores globales. Uno de los mayores retos fue manejar 25 ingestas con m√∫ltiples formatos, algunas con tablas de hasta 800 columnas, integraciones param√©tricas complejas y garantizar la automatizaci√≥n, encriptaci√≥n y validaci√≥n de datos sensibles.

### 2Ô∏è. Estrategias para mantener la arquitectura y pipelines de datos

- **Infraestructura como C√≥digo (IaC)** con Terraform para reproducibilidad y control de versiones.
- **Zonificaci√≥n de datos** (raw y processed) para trazabilidad y calidad.
- **Glue Crawlers + Jobs** para automatizar transformaciones de datos.
- **Lake Formation** para administraci√≥n de accesos a nivel de columna y tabla.
- **Redshift + QuickSight + SageMaker** para anal√≠tica y personalizaci√≥n.
- **Servicios serverless y gestionados**, como S3, Glue, Kinesis y Athena, para escalabilidad sin fricci√≥n.

### 3Ô∏è. Consideraciones al decidir entre S3, RDS o Redshift

| Servicio | Uso recomendado |
|----------|----------------|
| **Amazon S3** | Almacenamiento flexible, econ√≥mico y escalable para datos semiestructurados o sin procesar. |
| **Amazon RDS** | Ideal para consistencia ACID y relaciones fuertes en aplicaciones OLTP. |
| **Amazon Redshift** | An√°lisis avanzado sobre grandes vol√∫menes de datos estructurados con consultas r√°pidas. |

### 4Ô∏è. AWS Glue vs. Lambda vs. Step Functions para ETL

- **AWS Glue** ‚Üí Ideal para grandes vol√∫menes, manejo de metadatos y flujos complejos, pero con tiempos de arranque mayores.
- **AWS Lambda** ‚Üí Mejor para tareas peque√±as y eventos r√°pidos con ejecuci√≥n corta.
- **AWS Step Functions** ‚Üí Destaca en orquestaciones con l√≥gica condicional y flujos m√°s personalizados.

### 5Ô∏è. Garantizar la seguridad de los datos en un datalake en S3

- **IAM + Lake Formation** ‚Üí Control detallado de accesos.
- **Encriptaci√≥n en reposo y en tr√°nsito** ‚Üí Uso de SSE y TLS.
- **Versionado y pol√≠ticas de retenci√≥n** ‚Üí Restauraci√≥n de datos si es necesario.
- **Auditor√≠a con CloudTrail + CloudWatch** ‚Üí Monitoreo proactivo de eventos.
- **Validaci√≥n de integridad** ‚Üí Checksums y verificaciones en procesos ETL.
- **Bloqueo de accesos no autorizados** ‚Üí Pol√≠ticas de restricci√≥n por IP y permisos estrictos.

-----